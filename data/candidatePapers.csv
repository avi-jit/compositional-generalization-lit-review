"id","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"dbe286676d094ca588312cbfc8f699a9a2ca1cc9",8,"Structural generalization is hard for sequence-to-sequence models","","",2022,"Yuekun Yao,Alexander Koller",0,35,0,"https://www.semanticscholar.org/paper/dbe286676d094ca588312cbfc8f699a9a2ca1cc9"
"6e10343767ab09dde83cf99ea3442907402a9810",7,"Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing","Limits of current techniques for effectively leveraging model scale for compositional generalization are highlighted, while the analysis also suggests promising directions for future work.","ArXiv",2022,"Linlu Qiu,Peter Shaw,Panupong Pasupat,Tianze Shi,Jonathan Herzig,Emily Pitler,Fei Sha,Kristina Toutanova",3,83,1,"https://www.semanticscholar.org/paper/6e10343767ab09dde83cf99ea3442907402a9810"
"ef2522f15cafab8bafbabcd02ea8bf0fad6913b2",7,"Compositional Generalisation with Structured Reordering and Fertility Layers","This work presents a end-to-end differentiable neural model that composes two structural operations: a fertility step, which is introduced in this work, and a reordering step based on previous work, which outperforms seq2seq models by a wide margin on challenging compositional splits of realis-tic semantic parsing tasks.","ArXiv",2022,"Matthias Lindemann,Alexander Koller,Ivan Titov",0,46,0,"https://www.semanticscholar.org/paper/ef2522f15cafab8bafbabcd02ea8bf0fad6913b2"
"90c1a63aada7704eadc4324c16a66ec793d4b698",6,"Compositional generalization with a broad-coverage semantic parser","It is shown how the AM parser, a compositional semantic parser (Groschwitz et al., 2018) can solve compositional generalization on the COGS dataset and is the first semantic parser that achieves high accuracy on both naturally occurring language and the syntheticCOGS dataset.","STARSEM",2022,"Pia Weissenhorn,L. Donatelli,Alexander Koller",3,28,1,"https://www.semanticscholar.org/paper/90c1a63aada7704eadc4324c16a66ec793d4b698"
"00050c15896e8ae6bb534f10d072351547993f72",6,"LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing","This work shows that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence, and proposes LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph.","ArXiv",2021,"Dora Jambor,Dzmitry Bahdanau",0,38,0,"https://www.semanticscholar.org/paper/00050c15896e8ae6bb534f10d072351547993f72"
"5626e1db3d4fa8f8de79b604ce9fb8eb96a75883",6,"Improving Compositional Generalization with Latent Structure and Data Augmentation","This work presents a more powerful data recombination method using a model called Compositional Structure Learner (CSL), a generative model with a quasi-synchronous context-free grammar backbone, which results in a model even stronger than a T5-CSL ensemble on two real world compositional generalization tasks.","NAACL",2021,"Linlu Qiu,Peter Shaw,Panupong Pasupat,Pawel Krzysztof Nowak,Tal Linzen,Fei Sha,Kristina Toutanova",12,77,1,"https://www.semanticscholar.org/paper/5626e1db3d4fa8f8de79b604ce9fb8eb96a75883"
"a122909a31acf41cb2d9eb602c01b24b9b85a061",6,"LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing","This work shows that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence, and proposes LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph.","ACL",2022,"Dora Jambor,Dzmitry Bahdanau",1,37,0,"https://www.semanticscholar.org/paper/a122909a31acf41cb2d9eb602c01b24b9b85a061"
"559bfba3bee31f6061a5d5c7061f22794de47e39",6,"State-of-the-art generalisation research in NLP: a taxonomy and review","A taxonomy for characterising and understanding generalisation research in NLP is presented, a taxonomy is used to present a comprehensive map of published generalisation studies, and recommendations for which areas might deserve attention in the future are made.","ArXiv",2022,"D. Hupkes,Mario Giulianelli,Verna Dankers,Mikel Artetxe,Yanai Elazar,Tiago Pimentel,Christos Christodoulopoulos,Karim Lasri,Naomi Saphra,Arabella J. Sinclair,Dennis Ulmer,Florian Schottmann,Khuyagbaatar Batsuren,Kaiser Sun,Koustuv Sinha,Leila Khalatbari,Maria Ryskina,Rita Frieske,Ryan Cotterell,Zhijing Jin",1,690,0,"https://www.semanticscholar.org/paper/559bfba3bee31f6061a5d5c7061f22794de47e39"
"fcf25e1affc2f8ee5bb49d156f174e9769234deb",5,"Systematic Generalization with Edge Transformers","The Edge Transformer is a new model that combines inspiration from Transformers and rulebased symbolic AI that outperforms Relation-aware, Universal and classical Transformer baselines on compositional generalization benchmarks in relational reasoning, semantic parsing, and dependency parsing.","NeurIPS",2021,"Leon Bergen,T. O’Donnell,Dzmitry Bahdanau",3,46,0,"https://www.semanticscholar.org/paper/fcf25e1affc2f8ee5bb49d156f174e9769234deb"
"69078af65fc934f81fd340e9d1323d6c08194548",5,"Revisiting the Compositional Generalization Abilities of Neural Sequence Models","It is demonstrated that modifying the training distribution in simple and intuitive ways enables standard seq-to-seq models to achieve near-perfect generalization performance, thereby showing that their compositional generalization abilities were previously underestimated.","ACL",2022,"Arkil Patel,S. Bhattamishra,P. Blunsom,Navin Goyal",4,22,1,"https://www.semanticscholar.org/paper/69078af65fc934f81fd340e9d1323d6c08194548"
"6f0be1f9bda7530b1fa654cac84d595ca9d53740",4,"Revisit Systematic Generalization via Meaningful Learning","It is suggested that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively, and it is demonstrated that prior knowledge plays a key role as well.","",2020,"Ning Shi,Boxin Wang,Wei Wang,Xiangyu Liu,Zhouhan Lin",0,81,0,"https://www.semanticscholar.org/paper/6f0be1f9bda7530b1fa654cac84d595ca9d53740"
"b7b97fff93bcd32aa2d1c9bc1acc3827bb3d4347",4,"Sequence-to-Sequence Learning with Latent Neural Grammars","This work develops a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering, and applies it to a diagnostic language navigation task and to small-scale machine translation.","NeurIPS",2021,"Yoon Kim",11,150,3,"https://www.semanticscholar.org/paper/b7b97fff93bcd32aa2d1c9bc1acc3827bb3d4347"
"9a2ca811882ed7513f83014b9de4fb3b4ab218c4",4,"C OMPOSITIONAL G ENERALIZATION AND D ECOMPOSITION IN N EURAL P ROGRAM S YNTHESIS","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","",,"",0,0,0,"https://www.semanticscholar.org/paper/9a2ca811882ed7513f83014b9de4fb3b4ab218c4"
"4c430e6c3a72626bd4cb1893960c7c26dfec6c79",4,"Structurally Diverse Sampling Reduces Spurious Correlations in Semantic Parsing Datasets","This work proposes a novel algorithm for sampling a structurally diverse set of instances from a labeled instance pool with structured outputs that leads to better generalization and uses information theory to show that reduction in spurious correlations between substructures may be one reason why diverse training sets improve generalization.","ArXiv",2022,"Shivanshu Gupta,Sameer Singh,Matt Gardner",2,44,0,"https://www.semanticscholar.org/paper/4c430e6c3a72626bd4cb1893960c7c26dfec6c79"
"6a250b904965732840a75b6a13e35ac15f5cce4d",4,"Compositional Generalization and Decomposition in Neural Program Synthesis","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","ArXiv",2022,"Kensen Shi,Joey Hong,M. Zaheer,Pengcheng Yin,Charles Sutton",0,67,0,"https://www.semanticscholar.org/paper/6a250b904965732840a75b6a13e35ac15f5cce4d"
"c764ecba2bace12b9bfb9c2b0651a12ff6888ea7",4,"Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks","This work investigates learning representations that facilitate transfer learning from one compositional task to another: the representation and the task-specific layers of the models are strategically trained differently on a pre-finetuning task such that they generalize well on mismatched splits that require compositionality.","ArXiv",2021,"Wang Zhu,Peter Shaw,Tal Linzen,Fei Sha",3,51,0,"https://www.semanticscholar.org/paper/c764ecba2bace12b9bfb9c2b0651a12ff6888ea7"
"04ca71d9089b2e86f9e4a874fd66ee8bd0baba8e",4,"When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks","","",2022,"Ankur Sikarwar,Arkil Patel,Navin Goyal",0,32,0,"https://www.semanticscholar.org/paper/04ca71d9089b2e86f9e4a874fd66ee8bd0baba8e"
"676fa805bd715591f99bb17e36d673a6a14e92fe",4,"Finding needles in a haystack: Sampling Structurally-diverse Training Sets from Synthetic Data for Compositional Generalization","This work investigates automatic generation of synthetic utterance-program pairs for improving compositional generalization in semantic parsing and selects a subset of synthetic examples that are structurally-diverse and uses them to improve compositionalgeneralization.","EMNLP",2021,"I. Oren,Jonathan Herzig,Jonathan Berant",10,47,3,"https://www.semanticscholar.org/paper/676fa805bd715591f99bb17e36d673a6a14e92fe"
"bb0ab8591d6d57c7e2bd1ec35d806b3f25277752",4,"Inducing Transformer’s Compositional Generalization Ability via Auxiliary Sequence Prediction Tasks","It is argued that compositionality can be induced in Transformers given minimal but proper guidance, and a better result is achieved using less contextualized vectors as the attention’s query, providing insights into architecture choices in achieving systematic compositionality.","EMNLP",2021,"Yichen Jiang,Mohit Bansal",7,42,0,"https://www.semanticscholar.org/paper/bb0ab8591d6d57c7e2bd1ec35d806b3f25277752"
"c735740b26ceaa4db9d77233116434c0e8b311d8",4,"Learning Adaptive Control Flow in Transformers for Improved Systematic Generalization","The novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the compositional table lookup task, and its attention and gating patterns tend to be interpretable as an intuitive form of neural routing.","",2021,"R. Csordás,Kazuki Irie,J. Schmidhuber",0,36,0,"https://www.semanticscholar.org/paper/c735740b26ceaa4db9d77233116434c0e8b311d8"
"61d56ece2d19f4bfeb322c92085fb28521e169da",4,"Neural-Symbolic Recursive Machine for Systematic Generalization","The proposed Neural-Symbolic Recursive Machine (NSR) demonstrates stronger generalization than pure neural networks due to its symbolic representation and inductive biases, and demonstrates better transferability than existing neural-symbolic approaches due to less domain-speciﬁc knowledge required.","ArXiv",2022,"Qing Li,Yixin Zhu,Yitao Liang,Y. Wu,Song-Chun Zhu,Siyuan Huang",0,48,0,"https://www.semanticscholar.org/paper/61d56ece2d19f4bfeb322c92085fb28521e169da"
"b49ebf36a29cf9734313066129ab0d7092d4041e",4,"Categorizing Semantic Representations for Neural Machine Translation","The main idea is to enhance generalization by reducing sparsity and overfitting, which is achieved by finding prototypes of token representations over the training set and integrating their embeddings into the source encoding.","COLING",2022,"Yongjing Yin,Yafu Li,Fandong Meng,Jie Zhou,Yue Zhang",0,56,0,"https://www.semanticscholar.org/paper/b49ebf36a29cf9734313066129ab0d7092d4041e"
"da09949d0c89aca711de0f00e84138c62df623e1",3,"FROM SCAN TO REAL DATA: SYSTEMATIC GENER-","This paper revisits systematic generalization from the perspective of meaningful learning, an exceptional capability of humans to learn new concepts by connecting them with other previously known knowledge, and proposes to augment a training dataset in either an inductive or deductive manner to build semantic links between new and old concepts.","",2021,"Ning Shi,Boxin Wang,Wei Wang,Xiangyu Liu,Rong Zhang,Hui Xue,Xinbing Wang,Zhouhan Lin",1,49,0,"https://www.semanticscholar.org/paper/da09949d0c89aca711de0f00e84138c62df623e1"
"a406701b5fb05be55244d4f940db7be55fce85c6",3,"Semantic Systematicity in Connectionist Language Production","A novel connectionist model of sentence production that employs rich situation model representations originally proposed for modeling systematicity in comprehension, which provides a sufficient structure from which the neural network can interpret novel inputs.","Inf.",2021,"Jesús Calvillo,Harm Brouwer,M. Crocker",0,59,0,"https://www.semanticscholar.org/paper/a406701b5fb05be55244d4f940db7be55fce85c6"
"eaa88d697f92739f3569564329e9d037aabbe2d7",3,"A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics","Models show a gap toward human-level generalization when tested with new concepts in a few-shot setting, and the results suggest that current models still struggle in extrapolation to long-range syntactic dependency and semantics.","",2021,"Qing Li,Siyuan Huang,Yining Hong,Yixin Zhu,Y. Wu,Song-Chun Zhu",1,105,1,"https://www.semanticscholar.org/paper/eaa88d697f92739f3569564329e9d037aabbe2d7"
"76c9558b3fa10baf0e094386a650015b29a8a4bc",3,"Compositional generalization in semantic parsing with pretrained transformers","It is shown that language models pretrained exclusively with nonEnglish corpora, or even with programming language corporA, significantly improve out-of-distribution generalization in these benchmarks, compared with models trained from scratch, even though both benchmarks are English-based.","ArXiv",2021,"A. Orhan",3,25,0,"https://www.semanticscholar.org/paper/76c9558b3fa10baf0e094386a650015b29a8a4bc"
"a143cac1bc440135b612132c89e603f364b8a3b7",3,"Combine to Describe: Evaluating Compositional Generalization in Image Captioning","It is demonstrated that the models studied here do not compositionally generalize in terms of systematicity and productivity, however, they are robust to some degree to synonym substitutions.","ACL",2022,"G. Pantazopoulos,Alessandro Suglia,Arash Eshghi",1,57,0,"https://www.semanticscholar.org/paper/a143cac1bc440135b612132c89e603f364b8a3b7"
"66f3f0e8ebc780e570770986f50bf9cb9cd53ec1",3,"WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series Tasks","WOODS: eight challenging open-source time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and sensor signals is presented, underscoring the new challenges posed by time series tasks.","ArXiv",2022,"Jean-Christophe Gagnon-Audet,Kartik Ahuja,Mohammad Javad Darvishi Bayazi,G. Dumas,I. Rish",2,128,1,"https://www.semanticscholar.org/paper/66f3f0e8ebc780e570770986f50bf9cb9cd53ec1"
"bc16284f517dd0011dcf64ea1c8fe6d6576494a4",3,"Is the Computation of Abstract Sameness Relations Human-Like in Neural Language Models?","This work explores one facet of the question whether state-of-the-art NLP models exhibit elementary mechanisms known from human cognition by de-signed experimental settings in which each element from the original studies was mapped to a component of language models.","ArXiv",2022,"Lukas Thoma,Benjamin Roth",0,58,0,"https://www.semanticscholar.org/paper/bc16284f517dd0011dcf64ea1c8fe6d6576494a4"
"b1f33e956e36bf25e118c0d537dcc519cfe52e60",3,"CTL++: Evaluating Generalization on Never-Seen Compositional Patterns of Known Functions, and Compatibility of Neural Representations","CTL++ is introduced, a new diagnostic dataset based on compositions of unary symbolic functions designed to test systematicity of NNs, that is, their capability to generalize to unseen compositions of known functions.","ArXiv",2022,"R'obert Csord'as,Kazuki Irie,J. Schmidhuber",0,25,0,"https://www.semanticscholar.org/paper/b1f33e956e36bf25e118c0d537dcc519cfe52e60"
"1ed29beb55b10de8553c926ce6da2625ec2c8776",3,"Benchmarking Long-tail Generalization with Likelihood Splits","This work proposes a method to create challenging benchmarks that require generalizing to the tail of the distribution by re-splitting existing datasets by creating ‘Likeli-hood splits’ where examples that are assigned lower likelihood by a pre-trained language model are placed in the test set, and more likely examples are in the training set.","ArXiv",2022,"Ameya Godbole,Robin Jia",0,56,0,"https://www.semanticscholar.org/paper/1ed29beb55b10de8553c926ce6da2625ec2c8776"
"39f604fdd3ade5bd5a67d5284a6d9c12e535db85",3,"Compositionality as Lexical Symmetry","This paper proves that for any task factorizable into a lex013 icon and a composition function, there exists a family of data transformation functions that are guaranteed to produce new, well-formed examples when applied to training data and shows that it is possible to identify these transformations even when the compositional function is unknown.","ArXiv",2022,"Ekin Akyürek,Jacob Andreas",0,67,0,"https://www.semanticscholar.org/paper/39f604fdd3ade5bd5a67d5284a6d9c12e535db85"
"1167b3864046b732cf057b8b05db311e726cadab",3,"Measuring Alignment Bias in Neural Seq2seq Semantic Parsers","This work augments the popular Geo semantic parsing dataset with alignment annotations and creates Geo-Aligned, and studies the performance of standard seq2seq models on the examples that can be aligned monotonically versus examples that require more complex alignments.","STARSEM",2022,"Davide Locatelli,A. Quattoni",1,39,0,"https://www.semanticscholar.org/paper/1167b3864046b732cf057b8b05db311e726cadab"
"1bd799cf462f926041dd2fc8fbe4af54bddbf5c5",3,"Translate First Reorder Later: Leveraging Monotonicity in Semantic Parsing","By means of the monotonic translations, TP OL can learn reliable lexico-logical patterns from aligned data, improving compositional generalization both over conventional seq2seq models, as well as over a recently proposed approach that exploits gold alignments.","ArXiv",2022,"Francesco Cazzaro,Davide Locatelli,A. Quattoni,X. Carreras",0,43,0,"https://www.semanticscholar.org/paper/1bd799cf462f926041dd2fc8fbe4af54bddbf5c5"
"45496cd0b256b75bfbe3bd95890b496069c7821c",3,"Multilingual Compositional Wikidata Questions","This work proposes a method for creating a multilingual, parallel dataset of question-query pairs, grounded in Wikidata, and introduces such a dataset called CompositionalWikidata Questions (CWQ), and utilizes this data to train and evaluate semantic parsers for Hebrew, Kannada, Chinese and English, to better understand the current strengths and weaknesses of multilingual semantic parsing.","ArXiv",2021,"Ruixiang Cui,Rahul Aralikatte,Heather Christine Lent,Daniel Hershcovich",5,48,3,"https://www.semanticscholar.org/paper/45496cd0b256b75bfbe3bd95890b496069c7821c"
"ad331dce175b1d38d6516455013c1ec0e26e606b",3,"Compositional Generalization in Multilingual Semantic Parsing over Wikidata","A method is proposed for creating a multilingual, parallel dataset of question-query pairs, grounded in Wikidata, and it is used to analyze the compositional generalization of semantic parsers in Hebrew, Kannada, Chinese, and English.","Transactions of the Association for Computational Linguistics",2021,"Ruixiang Cui,Rahul Aralikatte,Heather Christine Lent,Daniel Hershcovich",1,82,0,"https://www.semanticscholar.org/paper/ad331dce175b1d38d6516455013c1ec0e26e606b"
"8008348e87d3904842a2dd230c14b83112e8bf48",3,"Compositional Generalization in Dependency Parsing","This work introduces a gold-standard set of dependency parses for CFQ, and uses this to analyze the behaviour of a state-of-the art dependency parser on the CFQ dataset, finding that increasing compound divergence degrades dependency parsing performance, although not as dramatically as semantic parsing performance.","ACL",2021,"Emily Goodwin,Siva Reddy,T. O’Donnell,Dzmitry Bahdanau",3,18,0,"https://www.semanticscholar.org/paper/8008348e87d3904842a2dd230c14b83112e8bf48"
"2b060b89324c376892a096c84fd14664f7b71710",3,"Understanding Robust Generalization in Learning Regular Languages","The empirical results support the hypothesis that auxiliary tasks can enable robust generalization, and theoretically prove that the compositional strategy generalizes significantly better than the end-to-end strategy.","ICML",2022,"Soham Dan,O. Bastani,D. Roth",1,37,0,"https://www.semanticscholar.org/paper/2b060b89324c376892a096c84fd14664f7b71710"
"03eeff98d24383518ce0dacc0b3c4a38b6f1a514",3,"Recursive Decoding: A Situated Cognition Approach to Compositional Generation in Grounded Language Understanding","Recursive Decoding (RD) is presented, a novel procedure for training and using seq2seq models, targeted towards decode-side generalization, which yields dramatic improvement on two previously neglected generalization tasks in gSCAN.","ArXiv",2022,"Matthew Setzler,Scott Howland,Lauren A. Phillips",0,34,0,"https://www.semanticscholar.org/paper/03eeff98d24383518ce0dacc0b3c4a38b6f1a514"
"3d5699e7f7e085ad72102859b06fa4884d207e77",3,"Iterative Decoding for Compositional Generalization in Transformers","This paper introduces iterative decoding, an alternative toseq2seq that improves transformer compositional generalization in the PCFG and Cartesian product datasets and evidences that, in these datasets, seq2seq transformers do not learn iterations that are not unrolled.","ArXiv",2021,"Luana Ruiz,J. Ainslie,Santiago Ontan'on",3,27,0,"https://www.semanticscholar.org/paper/3d5699e7f7e085ad72102859b06fa4884d207e77"
"a77468f6bd4db7f8d761a0569d9cc29d5a8f0034",3,"L OGIC I NFERENCE : A N EW D ATASET FOR T EACHING L OGICAL I NFERENCE TO SEQ 2 SEQ M ODELS","A new dataset to evaluate the ability of models to perform logical inference using propositional logic and a small subset of ﬁrst-order logic, represented both in semi-formal logical notation, as well as in natural language is presented.","",2022,"Santiago Ontañón,J. Ainslie,V. Cvicek,Zachary Kenneth Fisher",0,19,0,"https://www.semanticscholar.org/paper/a77468f6bd4db7f8d761a0569d9cc29d5a8f0034"
"e528466e2aff981511d4ca6e063211297c0b4175",3,"The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization","The novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the classic compositional table lookup task, as well as near-perfect accuracy on a simple arithmetic task and a new variant of ListOps testing for generalization across computational depths.","ICLR",2021,"R. Csordás,Kazuki Irie,J. Schmidhuber",7,60,2,"https://www.semanticscholar.org/paper/e528466e2aff981511d4ca6e063211297c0b4175"
"5021fd710fd17dee53bc7bc7bf334b148ef3d8b6",3,"LogicInference: A New Dataset for Teaching Logical Inference to seq2seq Models","A new dataset to evaluate the ability of models to perform logical inference using propositional logic and a small subset of ﬁrst-order logic, represented both in semi-formal logical notation, as well as in natural language is presented.","ArXiv",2022,"Santiago Ontañón,J. Ainslie,V. Cvicek,Zachary Kenneth Fisher",0,19,0,"https://www.semanticscholar.org/paper/5021fd710fd17dee53bc7bc7bf334b148ef3d8b6"
"837cc9a366c873c84ceec7e84d5cb3d5753757d6",3,"Systematic Generalization and Emergent Structures in Transformers Trained on Structured Tasks","This work shows that two-layer transformers learn generalizable solutions to multi-level problems and develop signs of systematic task decomposition, and provides key insights into how transformer models may be capable of decomposing complex decisions into reusable, multi- level policies in tasks requiring structured behavior.","ArXiv",2022,"Yuxuan Li,James L. McClelland",0,35,0,"https://www.semanticscholar.org/paper/837cc9a366c873c84ceec7e84d5cb3d5753757d6"
"97833e2aa0da5240e62436373b58af988a4ab6ab",3,"The Curious Case of Absolute Position Embeddings","","",2022,"Koustuv Sinha,Amirhossein Kazemnejad,Siva Reddy,J. Pineau,D. Hupkes,Adina Williams",0,56,0,"https://www.semanticscholar.org/paper/97833e2aa0da5240e62436373b58af988a4ab6ab"
"79cb080c84da314c2113692585b1e9ee29afa33a",2,"On learning an interpreted language with recurrent models","This work constructs simplified datasets reflecting core properties of natural language as modeled in formal syntax and semantics: recursive syntactic structure and compositionality, and finds LSTM and GRU networks to generalise to compositional interpretation well, but only in the most favorable learning settings.","",2018,"Denis Paperno",0,30,0,"https://www.semanticscholar.org/paper/79cb080c84da314c2113692585b1e9ee29afa33a"
"4b58367375466e653751a0c258b2f50bd3551408",2,"Sequence-to-Sequence Networks Learn the Meaning of Reflexive Anaphora","This paper considers sequence-to-sequence architectures with recurrent units and shows that such networks are capable of learning semantic interpretations for reflexive anaphora which generalize to novel antecedents.","CRAC",2020,"R. Frank,Jackson Petty",2,24,0,"https://www.semanticscholar.org/paper/4b58367375466e653751a0c258b2f50bd3551408"
"7ddb18fc67f13ff8ea5467bc04eb41666f8e7cb8",2,"AND does not mean OR: Using Formal Languages to Study Language Models’ Representations","None of the simulated training corpora result in models which definitively differentiate meaningfully different symbols (e.g., AND vs. OR), suggesting a limitation to the types of semantic signals that current models are able to exploit.","ACL",2021,"Aaron Traylor,Roman Feiman,Elizabeth-Jane Pavlick",7,17,0,"https://www.semanticscholar.org/paper/7ddb18fc67f13ff8ea5467bc04eb41666f8e7cb8"
"0b1470014bdbaa80ba63da0491d9db6c7d4febcc",2,"Detecting Compositionally Out-of-Distribution Examples in Semantic Parsing","This work investigates several strong yet simple methods for OOD detection based on predictive uncertainty and shows that these techniques perform well on the standard SCAN and CFQ datasets and can be improved by using a heterogeneous ensemble.","EMNLP",2021,"Denis Lukovnikov,Sina Däubener,Asja Fischer",1,30,0,"https://www.semanticscholar.org/paper/0b1470014bdbaa80ba63da0491d9db6c7d4febcc"
"acf8a1040034820bf99379a3422815f4e0859ec9",2,"Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?","NQG-T5 is proposed, a hybrid model that combines a high-precision grammar-based approach with a pre-trained sequence-to-sequence model that outperforms existing approaches across several compositional generalization challenges on non-synthetic data, while also being competitive with the state of theart on standard evaluations.","ACL",2020,"Peter Shaw,Ming-Wei Chang,Panupong Pasupat,Kristina Toutanova",72,67,17,"https://www.semanticscholar.org/paper/acf8a1040034820bf99379a3422815f4e0859ec9"