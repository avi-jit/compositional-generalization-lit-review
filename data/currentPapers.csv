"id","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"49e65b12d8d11f2ccb5ddd7be72a8f746b2d1bc2","Making Transformers Solve Compositional Tasks","This paper explores the design space of Transformer models showing that the inductive biases given to the model by several design decisions significantly impact compositional generalization.","ACL",2021,"Santiago Ontan'on,J. Ainslie,V. Cvicek,Zachary Kenneth Fisher",23,31,3,"https://www.semanticscholar.org/paper/49e65b12d8d11f2ccb5ddd7be72a8f746b2d1bc2"
"ab72bccf6f3981537389510ecc609109e79595c3","Disentangled Sequence to Sequence Learning for Compositional Generalization","An extension to sequence-to-sequence models which encourage disentanglement by adaptively re-encoding (at each time step) the source input by condition the source representations on the newly decoded target context which makes it easier for the encoder to exploit specialized information for each prediction.","ACL",2021,"Hao Zheng,Mirella Lapata",8,50,0,"https://www.semanticscholar.org/paper/ab72bccf6f3981537389510ecc609109e79595c3"
"d3edc20ed4a07195f3663abc0ead4220266fd75b","*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional Task","It is shown that compositional generalization remains a challenge at all training sizes, and that increasing the scope of natural language leads to consistently higher error rates, which are only partially offset by increased training data.","AAAI",2020,"D. Tsarkov,Tibor Tihon,Nathan Scales,Nikola Momchev,Danila Sinopalnikov,Nathanael Scharli",10,58,1,"https://www.semanticscholar.org/paper/d3edc20ed4a07195f3663abc0ead4220266fd75b"
"9fe39e0f2cf3b6d5f70a379654f9c08ffa48ddee","Unobserved Local Structures Make Compositional Generalization Hard","A criterion for the difficulty of an example is proposed: a test instance is hard if it contains a local structure that was not observed at training time and it predicts instance-level generalization well across 5 different semantic parsing datasets, substantially better than alternative decision rules.","",2022,"Ben Bogin,Shivanshu Gupta,Jonathan Berant",9,30,1,"https://www.semanticscholar.org/paper/9fe39e0f2cf3b6d5f70a379654f9c08ffa48ddee"
"40047a74b707743157051d38f76061ba5ff9aab4","Compositional Semantic Parsing with Large Language Models","The best method is based on least-to-most prompting: it decomposes the problem using prompting-based syntactic parsing, then uses this decomposition to select appropriate exemplars and to sequentially generate the semantic parse.","ArXiv",2022,"Andrew Drozdov,Nathanael Scharli,Ekin Akyuurek,Nathan Scales,Xinying Song,Xinyun Chen,O. Bousquet,Denny Zhou",3,62,0,"https://www.semanticscholar.org/paper/40047a74b707743157051d38f76061ba5ff9aab4"
"6d00b1024298e5b64ee873028385f7bb4396b05d","Learning Algebraic Recombination for Compositional Generalization","This paper proposes LEAR, an end-toend neural model to learn algebraic recombination for compositional generalization, to model the semantic parsing task as a homomorphism between a latent syntactic algebra and a semantic algebra, thus encouraging algebraic rewriting.","FINDINGS",2021,"Chenyao Liu,Shengnan An,Zeqi Lin,Qian Liu,Bei Chen,Jian-Guang Lou,L. Wen,Nanning Zheng,Dongmei Zhang",13,59,5,"https://www.semanticscholar.org/paper/6d00b1024298e5b64ee873028385f7bb4396b05d"
"856fe866bcce5e7a540655bea6ecc7406bdcfcba","Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks","This paper introduces the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences, and tests the zero-shot generalization capabilities of a variety of recurrent neural networks trained on SCAN with sequence-to-sequence methods.","ICML",2017,"B. Lake,Marco Baroni",463,50,74,"https://www.semanticscholar.org/paper/856fe866bcce5e7a540655bea6ecc7406bdcfcba"
"b20ddcbd239f3fa9acc603736ac2e4416302d074","COGS: A Compositional Generalization Challenge Based on Semantic Interpretation","In experiments with Transformers and LSTMs, it is found that in-distribution accuracy on the COGS test set was near-perfect, but generalization accuracy was substantially lower, and the dataset showed high sensitivity to random seed.","EMNLP",2020,"Najoung Kim,Tal Linzen",93,58,16,"https://www.semanticscholar.org/paper/b20ddcbd239f3fa9acc603736ac2e4416302d074"
"70a136547d81290b9f4dbc1fac49d31bc010bd3c","Meta-Learning to Compositionally Generalize","A meta-learning augmented version of supervised learning whose objective directly optimizes for out-of-distribution generalization is implemented, and Experimental results on the COGS and SCAN datasets show that this similarity-driven meta- learning can improve generalization performance.","ACL",2021,"Henry Conklin,Bailin Wang,Kenny Smith,Ivan Titov",29,46,5,"https://www.semanticscholar.org/paper/70a136547d81290b9f4dbc1fac49d31bc010bd3c"
"ed535e93d5b5a8b689e861e9c6083a806d1535c2","The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers","By revisiting model configurations as basic as scaling of embeddings, early stopping, relative positional embedding, and Universal Transformer variants, this work can drastically improve the performance of Transformers on systematic generalization.","EMNLP",2021,"R. Csordás,Kazuki Irie,J. Schmidhuber",46,55,10,"https://www.semanticscholar.org/paper/ed535e93d5b5a8b689e861e9c6083a806d1535c2"
"557ebd17b7c7ac4e09bd167d7b8909b8d74d1153","Compositional Generalization Requires Compositional Parsers","The accuracy of different 005 parsers on the recent COGS corpus is analyzed and the role of syntactic generalization in compo- 016 sitional generalization is analyzed.","ArXiv",2022,"Pia Weissenhorn,Yuekun Yao,L. Donatelli,Alexander Koller",0,40,0,"https://www.semanticscholar.org/paper/557ebd17b7c7ac4e09bd167d7b8909b8d74d1153"
"6e10343767ab09dde83cf99ea3442907402a9810","Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing","Limits of current techniques for effectively leveraging model scale for compositional generalization are highlighted, while the analysis also suggests promising directions for future work.","ArXiv",2022,"Linlu Qiu,Peter Shaw,Panupong Pasupat,Tianze Shi,Jonathan Herzig,Emily Pitler,Fei Sha,Kristina Toutanova",3,83,1,"https://www.semanticscholar.org/paper/6e10343767ab09dde83cf99ea3442907402a9810"
"ef2522f15cafab8bafbabcd02ea8bf0fad6913b2","Compositional Generalisation with Structured Reordering and Fertility Layers","This work presents a end-to-end differentiable neural model that composes two structural operations: a fertility step, which is introduced in this work, and a reordering step based on previous work, which outperforms seq2seq models by a wide margin on challenging compositional splits of realis-tic semantic parsing tasks.","ArXiv",2022,"Matthias Lindemann,Alexander Koller,Ivan Titov",0,46,0,"https://www.semanticscholar.org/paper/ef2522f15cafab8bafbabcd02ea8bf0fad6913b2"
"90c1a63aada7704eadc4324c16a66ec793d4b698","Compositional generalization with a broad-coverage semantic parser","It is shown how the AM parser, a compositional semantic parser (Groschwitz et al., 2018) can solve compositional generalization on the COGS dataset and is the first semantic parser that achieves high accuracy on both naturally occurring language and the syntheticCOGS dataset.","STARSEM",2022,"Pia Weissenhorn,L. Donatelli,Alexander Koller",3,28,1,"https://www.semanticscholar.org/paper/90c1a63aada7704eadc4324c16a66ec793d4b698"
"5626e1db3d4fa8f8de79b604ce9fb8eb96a75883","Improving Compositional Generalization with Latent Structure and Data Augmentation","This work presents a more powerful data recombination method using a model called Compositional Structure Learner (CSL), a generative model with a quasi-synchronous context-free grammar backbone, which results in a model even stronger than a T5-CSL ensemble on two real world compositional generalization tasks.","NAACL",2021,"Linlu Qiu,Peter Shaw,Panupong Pasupat,Pawel Krzysztof Nowak,Tal Linzen,Fei Sha,Kristina Toutanova",12,77,1,"https://www.semanticscholar.org/paper/5626e1db3d4fa8f8de79b604ce9fb8eb96a75883"
"69078af65fc934f81fd340e9d1323d6c08194548","Revisiting the Compositional Generalization Abilities of Neural Sequence Models","It is demonstrated that modifying the training distribution in simple and intuitive ways enables standard seq-to-seq models to achieve near-perfect generalization performance, thereby showing that their compositional generalization abilities were previously underestimated.","ACL",2022,"Arkil Patel,S. Bhattamishra,P. Blunsom,Navin Goyal",4,22,1,"https://www.semanticscholar.org/paper/69078af65fc934f81fd340e9d1323d6c08194548"
"c764ecba2bace12b9bfb9c2b0651a12ff6888ea7","Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks","This work investigates learning representations that facilitate transfer learning from one compositional task to another: the representation and the task-specific layers of the models are strategically trained differently on a pre-finetuning task such that they generalize well on mismatched splits that require compositionality.","ArXiv",2021,"Wang Zhu,Peter Shaw,Tal Linzen,Fei Sha",3,51,0,"https://www.semanticscholar.org/paper/c764ecba2bace12b9bfb9c2b0651a12ff6888ea7"
"04ca71d9089b2e86f9e4a874fd66ee8bd0baba8e","When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks","","",2022,"Ankur Sikarwar,Arkil Patel,Navin Goyal",0,32,0,"https://www.semanticscholar.org/paper/04ca71d9089b2e86f9e4a874fd66ee8bd0baba8e"
"bb0ab8591d6d57c7e2bd1ec35d806b3f25277752","Inducing Transformer’s Compositional Generalization Ability via Auxiliary Sequence Prediction Tasks","It is argued that compositionality can be induced in Transformers given minimal but proper guidance, and a better result is achieved using less contextualized vectors as the attention’s query, providing insights into architecture choices in achieving systematic compositionality.","EMNLP",2021,"Yichen Jiang,Mohit Bansal",7,42,0,"https://www.semanticscholar.org/paper/bb0ab8591d6d57c7e2bd1ec35d806b3f25277752"
"76c9558b3fa10baf0e094386a650015b29a8a4bc","Compositional generalization in semantic parsing with pretrained transformers","It is shown that language models pretrained exclusively with nonEnglish corpora, or even with programming language corporA, significantly improve out-of-distribution generalization in these benchmarks, compared with models trained from scratch, even though both benchmarks are English-based.","ArXiv",2021,"A. Orhan",3,25,0,"https://www.semanticscholar.org/paper/76c9558b3fa10baf0e094386a650015b29a8a4bc"
"39f604fdd3ade5bd5a67d5284a6d9c12e535db85","Compositionality as Lexical Symmetry","This paper proves that for any task factorizable into a lex013 icon and a composition function, there exists a family of data transformation functions that are guaranteed to produce new, well-formed examples when applied to training data and shows that it is possible to identify these transformations even when the compositional function is unknown.","ArXiv",2022,"Ekin Akyürek,Jacob Andreas",0,67,0,"https://www.semanticscholar.org/paper/39f604fdd3ade5bd5a67d5284a6d9c12e535db85"
"45496cd0b256b75bfbe3bd95890b496069c7821c","Multilingual Compositional Wikidata Questions","This work proposes a method for creating a multilingual, parallel dataset of question-query pairs, grounded in Wikidata, and introduces such a dataset called CompositionalWikidata Questions (CWQ), and utilizes this data to train and evaluate semantic parsers for Hebrew, Kannada, Chinese and English, to better understand the current strengths and weaknesses of multilingual semantic parsing.","ArXiv",2021,"Ruixiang Cui,Rahul Aralikatte,Heather Christine Lent,Daniel Hershcovich",5,48,3,"https://www.semanticscholar.org/paper/45496cd0b256b75bfbe3bd95890b496069c7821c"
"ad331dce175b1d38d6516455013c1ec0e26e606b","Compositional Generalization in Multilingual Semantic Parsing over Wikidata","A method is proposed for creating a multilingual, parallel dataset of question-query pairs, grounded in Wikidata, and it is used to analyze the compositional generalization of semantic parsers in Hebrew, Kannada, Chinese, and English.","Transactions of the Association for Computational Linguistics",2021,"Ruixiang Cui,Rahul Aralikatte,Heather Christine Lent,Daniel Hershcovich",1,82,0,"https://www.semanticscholar.org/paper/ad331dce175b1d38d6516455013c1ec0e26e606b"
"e528466e2aff981511d4ca6e063211297c0b4175","The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization","The novel Neural Data Router (NDR) achieves 100% length generalization accuracy on the classic compositional table lookup task, as well as near-perfect accuracy on a simple arithmetic task and a new variant of ListOps testing for generalization across computational depths.","ICLR",2021,"R. Csordás,Kazuki Irie,J. Schmidhuber",7,60,2,"https://www.semanticscholar.org/paper/e528466e2aff981511d4ca6e063211297c0b4175"
"dbe286676d094ca588312cbfc8f699a9a2ca1cc9","Structural generalization is hard for sequence-to-sequence models","","",2022,"Yuekun Yao,Alexander Koller",0,35,0,"https://www.semanticscholar.org/paper/dbe286676d094ca588312cbfc8f699a9a2ca1cc9"
"00050c15896e8ae6bb534f10d072351547993f72","LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing","This work shows that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence, and proposes LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph.","ArXiv",2021,"Dora Jambor,Dzmitry Bahdanau",0,38,0,"https://www.semanticscholar.org/paper/00050c15896e8ae6bb534f10d072351547993f72"
"a122909a31acf41cb2d9eb602c01b24b9b85a061","LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing","This work shows that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence, and proposes LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph.","ACL",2022,"Dora Jambor,Dzmitry Bahdanau",1,37,0,"https://www.semanticscholar.org/paper/a122909a31acf41cb2d9eb602c01b24b9b85a061"
"559bfba3bee31f6061a5d5c7061f22794de47e39","State-of-the-art generalisation research in NLP: a taxonomy and review","A taxonomy for characterising and understanding generalisation research in NLP is presented, a taxonomy is used to present a comprehensive map of published generalisation studies, and recommendations for which areas might deserve attention in the future are made.","ArXiv",2022,"D. Hupkes,Mario Giulianelli,Verna Dankers,Mikel Artetxe,Yanai Elazar,Tiago Pimentel,Christos Christodoulopoulos,Karim Lasri,Naomi Saphra,Arabella J. Sinclair,Dennis Ulmer,Florian Schottmann,Khuyagbaatar Batsuren,Kaiser Sun,Koustuv Sinha,Leila Khalatbari,Maria Ryskina,Rita Frieske,Ryan Cotterell,Zhijing Jin",1,690,0,"https://www.semanticscholar.org/paper/559bfba3bee31f6061a5d5c7061f22794de47e39"
"6f0be1f9bda7530b1fa654cac84d595ca9d53740","Revisit Systematic Generalization via Meaningful Learning","It is suggested that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively, and it is demonstrated that prior knowledge plays a key role as well.","",2020,"Ning Shi,Boxin Wang,Wei Wang,Xiangyu Liu,Zhouhan Lin",0,81,0,"https://www.semanticscholar.org/paper/6f0be1f9bda7530b1fa654cac84d595ca9d53740"
"9a2ca811882ed7513f83014b9de4fb3b4ab218c4","C OMPOSITIONAL G ENERALIZATION AND D ECOMPOSITION IN N EURAL P ROGRAM S YNTHESIS","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","",,"",0,0,0,"https://www.semanticscholar.org/paper/9a2ca811882ed7513f83014b9de4fb3b4ab218c4"
"6a250b904965732840a75b6a13e35ac15f5cce4d","Compositional Generalization and Decomposition in Neural Program Synthesis","A suite of generalization tasks, which measure different types of compositional generalization that are desirable for program synthesis and are particularly difﬁcult for current sequence to sequence models, are proposed.","ArXiv",2022,"Kensen Shi,Joey Hong,M. Zaheer,Pengcheng Yin,Charles Sutton",0,67,0,"https://www.semanticscholar.org/paper/6a250b904965732840a75b6a13e35ac15f5cce4d"
"a143cac1bc440135b612132c89e603f364b8a3b7","Combine to Describe: Evaluating Compositional Generalization in Image Captioning","It is demonstrated that the models studied here do not compositionally generalize in terms of systematicity and productivity, however, they are robust to some degree to synonym substitutions.","ACL",2022,"G. Pantazopoulos,Alessandro Suglia,Arash Eshghi",1,57,0,"https://www.semanticscholar.org/paper/a143cac1bc440135b612132c89e603f364b8a3b7"